---
title: "MCP を活用した GUI から AI 対話への転換"
emoji: "🐕"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["mcp", "llm", "ecs", "anthropic"]
published: true
---
MCP（Model Context Protocol）の可能性とその実現方法について紹介します。

![alt text](/images/723f0416882058-a.png)
*図 1. LLM がツール呼び出し、MCP クライアント（GitHub Copilot）はそれを MCP サーバーに転送しサーバーがツールを実行。ツールの実行結果は LLM に送られ最終回答がユーザーに返される*

## tl;dr

- MCP を活用することで、業務をより直感的かつ効率的に遂行できる可能性があります。
- MCP は、LLM モデルと API を連携させ、業務の効率化を図ることができます。

## 前提

どこの会社でも同じだと思いますが、業務において複数のシステムやツールを使い分けて業務を行っており、作業の煩雑さが課題だと考えています。
また、生成 AI の急速な発展により、従来の GUI 中心のインターフェースから AI との自然な対話による業務遂行への転換の可能性が現実味を帯びてきました。

このような背景から、MCP を活用して業務を効率化し、より直感的かつ効率的に業務を遂行できる環境を構築することが可能になって来ていると考えています。本記事では、その実現方法について書きます。

https://docs.anthropic.com/ja/docs/agents-and-tools/mcp

### 従来の Web UI の存在意義の変化

生成 AI の進化により、プロダクトが提供する価値が大きく変化しています。アプリは従来の GUI の存在意義が薄れ、最終的には AI との対話が中心となる時代が近づいていると考えています。この変化に対応するため、Interface を AI との対話に最適化する必要があると考えています。

## 戦略

前述の課題と変化を踏まえ、MCP を中心としたプローチが有効だと考えています。業務効率を向上させながら、将来的な AI を中心としたインターフェースへの移行を実現することが可能だと思います。

### ツールの提供

ご存知の通り、LLM モデルは、ツールを使って外部 API を呼び出すことができます。API を LLM モデルに提供し、業務を遂行する際に必要な情報を迅速に取得できるようになりました。

### MCP with Streamable HTTP

MCP サーバーは、ツールからのデータをストリーミング形式で LLM モデルに提供し、リアルタイムでの情報取得を可能にします。
また、Streamable HTTP を採用することで、MCP は幅広いアプリケーションに対応できるようになると考えています。

![architecture](/images/723f0416882058-c.png)

![alt text](/images/723f0416882058-d.png)
*図 2. MCP アーキテクチャ（サンプル）*

## まとめ

私は MCP を活用することで、業務の効率化が可能になると考えています。LLM モデルと API を連携させることで、業務の遂行がより直感的かつ効率的に行えるようになるでしょう。
生成 AI を中心としたアプローチを採用し、より直感的かつ効率的に業務を遂行できる環境を構築することが可能になると信じています。

記事は以上です。
